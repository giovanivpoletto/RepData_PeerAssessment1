a <- available.packages()
head(rownames(a),3)
head(rownames(i),3)
head(rownames(a),s)
install.packages("slidify")
install.packages(c("ggplot2", "devtools"))
source("http://bioconductor.org/biocLite.R")
biocLite()
biocLite(c("GenomicFeatures", "AnnotationDbi"))
lybrary()
library()
library(ggplot2)
search()
q()
install.packages("KernSmooth")
library(KernSmooth)
q()
find.package("devtool")
find.package("devtools")
install.packages("devtools")
library(devtools)
find_rtools
data <- htmlTreeParse(fileName, useInternalNodes = T)
View(a)
# Find all linkedin links in the comments.
require(XML)
require(stringr)
#
# Grabs all LinkedIn urls from a Coursera forum thread. Perfect for the "Let's Connect!" threads.
# Usage:
# 1. Open a Coursera forum thread, containing LinkedIn links.
# 2. Scroll all the way to the bottom of the page to load all posts in the thread.
# 3. Save the web page to an html file named post.htm.
# 4. Call linkedInLinks("post.htm")
# 5. To save the result to a file: write.csv(linkedInLinks("post.htm"), "links.csv", quote=FALSE, row.names=FALSE)
#
linkedInLinks <- function(fileName) {
# Read html page from file.
data <- htmlTreeParse(fileName, useInternalNodes = T)
# Find all linkedin links in the comments.
commentElements <- xpathApply(data, "//div[@class='course-forum-post-text']//a[contains(@href, 'linkedin')]")
# Get the href value for each link.
sapply(commentElements, function(el) xmlGetAttr(el, "href"))
}
cube <- function(x, n){}
cube <- function(x, n){ X^3 }
cube(3)
cube(3)
cube
cube <- function(x, n){ X ^ 3 }
cube
cube(3)
cube <- function(x, n){
x^3
}
cube(3)
cube <- function(x, n){
X^3
}
cube(3)
cube <- function(x, n){
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
h <- function(x, y = NULL, d = 3L) {
z <- cbind(x, d)
if(!is.null(y))
z <- z + y
else
z <- z + f
g <- x + y / z
if(d == 3L)
return(g)
g <- g + 10
g
}
f
z
d
h
x(5)
h(5)
h(5, 3)
d
g
h(5)
h <- function(x, y = NULL, d = 3L) {
z <- cbind(x, d)
if(!is.null(y))
z <- z + y
else
z <- z + f
g <- x + y / z
if(d == 3L)
return(g)
g <- g + 10
g
}
h
h(5)
f<- 5
h(5)
h(5, 3)
f <- function(x){
y <- 2
y^2 + g(x)
}
g <- function(x){
x*y
}
f(3)
y <- 10
f(3)
`001` <- read.csv("~/04-cursos/01-data-scientist/05-R-Programming/03-data/specdata/001.csv")
View(`001`)
001
001[1,1]
001[1]
001[2]
001[, 2]
dim(001)
?dim
length(001)
x <- data.frame(001)
x
library(datasets)
data(iris)
?iris
iris
apply(iris,2,mean)
mean
apply(iris,2,mean(Sepal.Length))
x <- matrix(rnorm(200),20,10)
x
apply(x,2,mean)
apply(iris[,"Sepal.length"],2,mean)
head(iris)
apply(iris[,"Sepal.Length"],2,mean)
iris["Sepal.Length"]
apply(iris["Sepal.Length"],2,mean)
apply(iris,2,mean)
apply(iris, 2, mean)
apply(iris[,1:4], 2, mean)
apply(iris[,1:4], 1, mean)
apply(iris[,1:4], 2, mean)
library(datasets)
data(mtcars)
mtcars
class(mtcars)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
View(`001`)
View(`001`)
sapply(split(mtcars$hp, mtcars$cyl), mean)
x <- sapply(split(mtcars$hp, mtcars$cyl), mean)
x
?abs
class(x)
y <- x[4]
y
y <- x[,4]
x
x[[4]]
dim(x)
length(x)
names(x)
x[[1]]
x[[2]]
x[[3]]
x[["4"]]
y <- x[["4"]] - x[["8"]]
y
abs(y)
z <- abs(x[["4"]]) - abs(x[["8"]])
z
y
debug(ls)
?debug
ls
ls()
q
q
w
2
undebug
undebug(ls)
ls
ls()
?Browser
help
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "f9ee1b81db0f0a3e4c005405e4b5782c05395c61")
env
myapp <- oauth_app("github", "f9ee1b81db0f0a3e4c005405e4b5782c05395c61")
q()
myapp <- oauth_app("github", "f9ee1b81db0f0a3e4c005405e4b5782c05395c61")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "f9ee1b81db0f0a3e4c005405e4b5782c05395c61")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
url <- "https://api.github.com/users/jtleek/repos"
url
oauth_endpoints("github")
?oauth_endpoints
myapp <- oauth_app("github", key="9a7485d99d16d19c362b",secret="725eb30d7ee136fbd9e9578236794698bd606a4a")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httpuv)
install.packages("httpuv")
library(httpuv)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
install.packages("jsonlite")
library(jsonlite)
content(req)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
content(req)
content(req)$created_at
content(req$created_at)
req
class(req)
DT <- content(req)
DT
class(DT)
DT$created_at
remove(DT)
DT <- fromJSON("https://api.github.com/users/jtleek/repos")
names(DT)
names(DT$owner)
names(DT$html_urls)
names(DT$html_url)
DT$html_url
DT$created_at
sort(DT$created_at)
DT$html_url
DT$created_at[5]
q()
library(lattice)
q()
library(lattice)
xyplot()
bwplot
bwplot()
xyplot
library(datasets)
?xyplot
library(lattice)
?lpoints
?points
install.packages("ggplot2")
library(ggplot2)
install.packages('ggplot2', dep = TRUE)
library(ggplot2)
install.packages("proto")
library(ggplot2)
remove.packages(c("ggplot2", "data.table"))
install.packages('Rcpp', dependencies = TRUE)
install.packages('ggplot2', dependencies = TRUE)
install.packages('data.table', dependencies = TRUE)
library(ggplot2)
update.packages("ggplot2")
library(ggplot2)
iinstall.packages("devtools")
install.packages("devtools")
library(ggplot2)
install.packages("AES")
install.packages("digest")
install.packages("hmac")
library(ggplot2)
remove.packages("ggplot2", lib="~/R/win-library/3.1")
install.packages('ggplot2', dep = TRUE, type = "source")
remove.packages("digest", lib="~/R/win-library/3.1")
install.packages('ggplot2', dep = TRUE, type = "source")
install.packages("ggplot2", dep = TRUE, type = "source")
install.packages("ggplot2", dep = TRUE, type = "source", repos = "http://cran.r-project.org")
install.packages(c("base64enc", "BatchJobs", "BBmisc", "BH", "chron", "colorspace", "dplyr", "evaluate", "fail", "foreach", "formatR", "gsubfn", "highr", "htmltools", "httpuv", "httr", "iterators", "jsonlite", "KernSmooth", "knitr", "labeling", "manipulate", "markdown", "mime", "plyr", "quantmod", "R6", "RColorBrewer", "RCurl", "reshape2", "rJava", "rmarkdown", "roxygen2", "RSQLite", "rstudioapi", "scales", "sendmailR", "sqldf", "stringr", "swirl", "testthat", "TTR", "xlsxjars", "XML", "zoo"))
library(ggplot2)
install.packages("ggplot2", dep = TRUE, type = "source", repos = "http://cran.r-project.org")
library(ggplot2)
install.packages('Rcpp', dependencies = TRUE)
install.packages('ggplot2', dependencies = TRUE)
setwd("~/04-cursos/01-data-scientist/09-reproducible-research/02-workspace")
install.packages('data.table', dependencies = TRUE)
index <- 1
library(ggplot2)
library(ggplot2)
source('~/04-cursos/01-data-scientist/09-reproducible-research/02-workspace/RepData_PeerAssessment1/PA1_code.R', echo=TRUE)
setwd("~/04-cursos/01-data-scientist/09-reproducible-research/02-workspace/RepData_PeerAssessment1")
source('~/04-cursos/01-data-scientist/09-reproducible-research/02-workspace/RepData_PeerAssessment1/PA1_code.R', echo=TRUE)
source('~/04-cursos/01-data-scientist/09-reproducible-research/02-workspace/RepData_PeerAssessment1/PA1_code.R', echo=TRUE)
str(rawactivity)
class(datavector)
class(datevector)
summary(datevector)
help(mean())
help(mean
)
mean(cleandata)
mean(cleandata[1,])
mean(cleandata[,1])
mean(cleandata[,1], na.rm = TRUE)
mean(cleandata[,2], na.rm = TRUE)
mean(cleandata[,3], na.rm = TRUE)
meandata()
meandata
reportmeanmedian
head(maxsteps,1)[,2]
tail(summary(rawactivity),1)[,1]
